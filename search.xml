<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>小白学django搭建网站</title>
    <url>/2020/05/10/django%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>django是一个python语言开发的web框架。<br>主要的组件以及特点</p>
<ul>
<li>强大的数据库功能</li>
<li>自带后台管理功能</li>
<li>优雅的网址</li>
<li>模板系统</li>
<li>缓存系统</li>
<li>国际化</li>
</ul>
<h3 id="1-搭建项目"><a href="#1-搭建项目" class="headerlink" title="1 搭建项目"></a>1 搭建项目</h3><p>安装python2.7或者python3均可，安装pip（默认都有啦）</p>
<h4 id="1-1-安装django"><a href="#1-1-安装django" class="headerlink" title="1.1 安装django"></a>1.1 安装django</h4><p>默认安装最新版</p>
<p><code>(sudo) pip install django</code></p>
<p>指定版本安装</p>
<p><code>(sudo) pip install django==1.11.11</code></p>
<p>安装如果遇到速度太慢或者超时，可以使用国内镜像安装</p>
<p><code>(sudo) pip install django -i https://pypi.doubanio.com/simple/</code></p>
<p>安装后就可以下一步搭建项目</p>
<h4 id="1-2-创建一个django项目"><a href="#1-2-创建一个django项目" class="headerlink" title="1.2 创建一个django项目"></a>1.2 创建一个django项目</h4><h5 id="1-2-1-创建一个项目目录（已有也行）"><a href="#1-2-1-创建一个项目目录（已有也行）" class="headerlink" title="1.2.1 创建一个项目目录（已有也行）"></a>1.2.1 创建一个项目目录（已有也行）</h5><p><code>mkdir django_test</code></p>
<h5 id="1-2-2-进入该目录"><a href="#1-2-2-进入该目录" class="headerlink" title="1.2.2 进入该目录"></a>1.2.2 进入该目录</h5><p><code>cd django_test</code></p>
<h5 id="1-2-3-执行该命令创建一个django项目"><a href="#1-2-3-执行该命令创建一个django项目" class="headerlink" title="1.2.3 执行该命令创建一个django项目"></a>1.2.3 执行该命令创建一个django项目</h5><p><code>django-admin.py startproject family</code></p>
<h5 id="1-2-4-进入family目录后执行"><a href="#1-2-4-进入family目录后执行" class="headerlink" title="1.2.4 进入family目录后执行"></a>1.2.4 进入family目录后执行</h5><p><code>python manage.py runserver</code> 或者指定端口 <code>python manage.py runserver 8081</code></p>
<p>在浏览器输入 <a href="http://127.0.0.1:8000/" target="_blank" rel="noopener">http://127.0.0.1:8000/</a> 就可以打开看到 It worked! 字样，表示django项目创建成功</p>
<h4 id="1-3-创建一个django工程"><a href="#1-3-创建一个django工程" class="headerlink" title="1.3 创建一个django工程"></a>1.3 创建一个django工程</h4><p><code>python manage.py startapp family_app</code></p>
<p>注意点：工程名中不能有中划线</p>
<h4 id="1-4-配置我们的工程"><a href="#1-4-配置我们的工程" class="headerlink" title="1.4 配置我们的工程"></a>1.4 配置我们的工程</h4><p>需要在family/settings.py中做一些配置</p>
<h5 id="1-4-1-INSTALLED-APPS列表中注册我们的工程名"><a href="#1-4-1-INSTALLED-APPS列表中注册我们的工程名" class="headerlink" title="1.4.1 INSTALLED_APPS列表中注册我们的工程名"></a>1.4.1 INSTALLED_APPS列表中注册我们的工程名</h5><h5 id="1-4-2-配置数据库-mysql"><a href="#1-4-2-配置数据库-mysql" class="headerlink" title="1.4.2 配置数据库(mysql)"></a>1.4.2 配置数据库(mysql)</h5><p>默认我们本地都安装了mysql（建议5.6+）<br>在DATABASES字典中注释掉自带的数据库，使用我们自己配置的mysql</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> &#39;default&#39;: &#123;</span><br><span class="line">    &#39;ENGINE&#39;: &#39;django.db.backends.mysql&#39;,</span><br><span class="line">    &#39;NAME&#39;: &#39;family_app&#39;,</span><br><span class="line">    &#39;USER&#39;: &#39;wanglei&#39;,</span><br><span class="line">    &#39;PASSWORD&#39;: &#39;xxxxxx&#39;,</span><br><span class="line">    &#39;HOST&#39;: &#39;127.0.0.1&#39;,</span><br><span class="line">    &#39;PORT&#39;: &#39;3306&#39;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>

<p>注意点：如果mysql版本是5.7+，需要在family/<strong>init</strong>.py中加入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pymysql</span><br><span class="line">pymysql.install_as_MySQLdb()</span><br></pre></td></tr></table></figure>
<p>原因是直接使用mysql和mysqlDb的不兼容，不能直接使用mysqlDb模块，需要使用pymysql替代</p>
<h5 id="1-4-3-数据库中创建一些django自带的表"><a href="#1-4-3-数据库中创建一些django自带的表" class="headerlink" title="1.4.3 数据库中创建一些django自带的表"></a>1.4.3 数据库中创建一些django自带的表</h5><p><code>python manage.py migrate</code></p>
<p>到此为止，整个项目和工程的基本配置就完成了。</p>
<h3 id="2-helloWorld起步"><a href="#2-helloWorld起步" class="headerlink" title="2 helloWorld起步"></a>2 helloWorld起步</h3><h4 id="2-1-工程中的文件结构介绍"><a href="#2-1-工程中的文件结构介绍" class="headerlink" title="2.1 工程中的文件结构介绍"></a>2.1 工程中的文件结构介绍</h4><ul>
<li>migrations：数据迁移模块</li>
<li>admin.py：后台管理系统</li>
<li>apps.py：应用的一些配置，1.9以后自动生成</li>
<li>models.py：数据模块</li>
<li>tests.py：自动化测试的模块</li>
<li>views.py：执行响应的代码所在模块，是代码逻辑处理的主要地点，项目中大部分代码在这里编写</li>
</ul>
<h4 id="2-2-第一行代码"><a href="#2-2-第一行代码" class="headerlink" title="2.2 第一行代码"></a>2.2 第一行代码</h4><ul>
<li><p>在family/urls.py中引入我们工程中的views，然后配置路由</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import family_app.views as views</span><br><span class="line">urlpatterns &#x3D; [</span><br><span class="line">    url(r&#39;^admin&#x2F;&#39;, admin.site.urls),</span><br><span class="line">    url(r&#39;^$&#39;, views.index),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</li>
<li><p>family_app/views.py中写我们要展示在界面的逻辑</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from django.http import HttpResponse, JsonResponse</span><br><span class="line">def index(request):</span><br><span class="line">    ret_str &#x3D; &quot;hello world&quot;</span><br><span class="line">    print ret_str</span><br><span class="line">    return HttpResponse(ret_str)</span><br></pre></td></tr></table></figure>
</li>
<li><p>刷新界面，就可以看到hello world了</p>
</li>
</ul>
<h3 id="3-渲染模板"><a href="#3-渲染模板" class="headerlink" title="3 渲染模板"></a>3 渲染模板</h3><h4 id="3-1-模板渲染入门"><a href="#3-1-模板渲染入门" class="headerlink" title="3.1 模板渲染入门"></a>3.1 模板渲染入门</h4><p>将后端返回的结构化数据渲染到模板上</p>
<ul>
<li><p>在family_app目录下创建templates目录，管理前端模板</p>
</li>
<li><p>在family/settings.py的TEMPLATES中DIRS列表中加入’family_app/templates’</p>
</li>
<li><p>在templates目录下创建index.html文件，并写代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang&#x3D;&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset&#x3D;&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;Title&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        &lt;h3&gt;这就是后端返回的数据 &#123;&#123; data &#125;&#125;&lt;&#x2F;h3&gt;</span><br><span class="line">    &lt;&#x2F;div&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>family_app/views.py中修改响应的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">return render(request, &#39;index.html&#39;, &#123;&#39;data&#39;: ret_str&#125;)</span><br></pre></td></tr></table></figure>
<p>一个简单的模板渲染就完成了</p>
</li>
</ul>
<h4 id="3-2-一些基础的渲染方式"><a href="#3-2-一些基础的渲染方式" class="headerlink" title="3.2 一些基础的渲染方式"></a>3.2 一些基础的渲染方式</h4><ul>
<li>列表渲染</li>
</ul>
<p>family_app/views.py</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ret_str &#x3D; [&quot;hello world&quot;, &quot;1024&quot;]</span><br><span class="line">return render(request, &#39;index.html&#39;, &#123;&#39;data&#39;: ret_str&#125;)</span><br></pre></td></tr></table></figure>
<p>templates/index.html</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% for item in data %&#125;</span><br><span class="line">        &lt;p&gt;&#123;&#123; item &#125;&#125;&lt;&#x2F;p&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>字典渲染<br>family_app/views.py<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ret_str &#x3D; &#123;&quot;k1&quot;: &quot;hello&quot;, &quot;k2&quot;: &quot;world&quot;, &quot;k3&quot;: &quot;1024&quot;&#125;</span><br><span class="line">return render(request, &#39;index.html&#39;, &#123;&#39;data&#39;: ret_str&#125;)</span><br></pre></td></tr></table></figure>
templates/index.html<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">遍历取值</span><br><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% for key, val in data.items %&#125;</span><br><span class="line">        &lt;p&gt;key:&#123;&#123; key &#125;&#125; val:&#123;&#123; val &#125;&#125;&lt;&#x2F;p&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">按key取值</span><br><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;&#123; data.k3 &#125;&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>4 包含静态资源的模板渲染</p>
<p>在以上的基础上，我们加上js和css的操作</p>
<ul>
<li><p>在family_app目录下创建static目录，管理静态资源</p>
</li>
<li><p>在family/settings.py中添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">STATIC_ROOT &#x3D; os.path.join(BASE_DIR, &quot;family_app&#x2F;static&quot;)</span><br></pre></td></tr></table></figure></li>
<li><p>在family_app/static/index.js，并添加代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function click_submit()</span><br><span class="line">&#123;</span><br><span class="line">    alert(&quot;别点了！&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在family_app/static/index.css，并添加代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.list-css &#123;</span><br><span class="line">    margin-left:200px;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在index.html中添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% load static %&#125;</span><br><span class="line">&lt;link rel&#x3D;&quot;stylesheet&quot; href&#x3D;&quot;&#123;% static &#39;index.css&#39; %&#125;&quot; type&#x3D;&quot;text&#x2F;css&quot;&gt;</span><br><span class="line">&lt;script src&#x3D;&quot;static&#x2F;index.js&quot;&gt;&lt;&#x2F;script&gt;</span><br><span class="line"></span><br><span class="line">&lt;div onclick&#x3D;&quot;click_submit()&quot;&gt;点击按钮&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>以上就是前端静态资源在页面加载过程中的具体配置方式</p>
<h3 id="4-后端请求数据库"><a href="#4-后端请求数据库" class="headerlink" title="4 后端请求数据库"></a>4 后端请求数据库</h3><p>先不使用django的model，我们自己连接数据库去请求</p>
<h4 id="4-1-创建数据库表并写几条数据进去"><a href="#4-1-创建数据库表并写几条数据进去" class="headerlink" title="4.1 创建数据库表并写几条数据进去"></a>4.1 创建数据库表并写几条数据进去</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table family_app.user (</span><br><span class="line">  id int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  number bigint(20) NOT NULL COMMENT &#39;用户编号&#39;,</span><br><span class="line">  name varchar(45) DEFAULT NULL COMMENT &#39;用户名&#39;,</span><br><span class="line">  mobile varchar(20) DEFAULT NULL COMMENT &#39;手机号&#39;,</span><br><span class="line">  status tinyint(4) DEFAULT &#39;1&#39; COMMENT &#39;用户状态&#39;,</span><br><span class="line">  create_time timestamp DEFAULT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  update_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;,</span><br><span class="line">  PRIMARY KEY (id),</span><br><span class="line">  UNIQUE KEY uniq_number (number),</span><br><span class="line">  KEY idx_mobile (mobile),</span><br><span class="line">  KEY idx_update_time (update_time)</span><br><span class="line">) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;0 DEFAULT CHARSET&#x3D;utf8 COMMENT&#x3D;&quot;用户表&quot;;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into family_app.user (number, name, mobile, status) values (1000, &quot;张三&quot;, &quot;13100000000&quot;, 1);</span><br></pre></td></tr></table></figure>

<h4 id="4-2-连接数据库并写sql请求数据"><a href="#4-2-连接数据库并写sql请求数据" class="headerlink" title="4.2 连接数据库并写sql请求数据"></a>4.2 连接数据库并写sql请求数据</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from django.db import connection, models</span><br><span class="line">import traceback</span><br><span class="line"></span><br><span class="line">def get_user_info(request):</span><br><span class="line">    number &#x3D; 0</span><br><span class="line">    if &#39;number&#39; in request.GET and request.GET[&#39;number&#39;] !&#x3D; 0:</span><br><span class="line">        number &#x3D; int(request.GET[&#39;number&#39;])</span><br><span class="line"></span><br><span class="line">    user_sql &#x3D; &quot;&quot;&quot;</span><br><span class="line">        select number, name, mobile from family_app.user where status&#x3D;1 and number&#x3D;%s</span><br><span class="line">    &quot;&quot;&quot; % number</span><br><span class="line">    print &quot;user_sql:&quot;, user_sql</span><br><span class="line">    ret &#x3D; execute(user_sql)</span><br><span class="line"></span><br><span class="line">    ret_list &#x3D; []</span><br><span class="line">    for r in ret:</span><br><span class="line">        print r[0], r[1], r[2]</span><br><span class="line">        user_dict &#x3D; &#123;&quot;number&quot;: r[0], &quot;name&quot;: r[1], &quot;mobile&quot;: r[2]&#125;</span><br><span class="line">        ret_list.append(user_dict)</span><br><span class="line">    return render(request, &#39;index.html&#39;, &#123;&#39;data&#39;: ret_list&#125;)</span><br><span class="line"></span><br><span class="line">def execute(sql, params&#x3D;None, auto_close&#x3D;True):</span><br><span class="line">    cur &#x3D; None</span><br><span class="line">    try:</span><br><span class="line">        sql &#x3D; sql.strip()</span><br><span class="line">        cur &#x3D; connection.cursor()</span><br><span class="line">        cur.execute(sql, params)</span><br><span class="line">        result &#x3D; cur.fetchall()</span><br><span class="line">        #print &quot;ret_len:&quot;, len(result)</span><br><span class="line">        return result</span><br><span class="line">    except Exception, e:</span><br><span class="line">        if params:</span><br><span class="line">            print sql % params</span><br><span class="line">        else:</span><br><span class="line">            print sql</span><br><span class="line">        traceback.print_exc()</span><br><span class="line">    finally:</span><br><span class="line">        if cur and auto_close:</span><br><span class="line">            cur.close()</span><br></pre></td></tr></table></figure>

<h4 id="4-3-url配置接口名"><a href="#4-3-url配置接口名" class="headerlink" title="4.3 url配置接口名"></a>4.3 url配置接口名</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url(r&#39;^get_user_info&#39;, views.get_user_info)</span><br></pre></td></tr></table></figure>

<h4 id="4-4-index-html中写渲染代码"><a href="#4-4-index-html中写渲染代码" class="headerlink" title="4.4 index.html中写渲染代码"></a>4.4 index.html中写渲染代码</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% for item_dict in data %&#125;</span><br><span class="line">        &#123;% for key, val in item_dict.items %&#125;</span><br><span class="line">            &lt;p&gt;key:&#123;&#123; key &#125;&#125; val:&#123;&#123; val &#125;&#125;&lt;&#x2F;p&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure>

<p>以上开发和配置完成后浏览器访问 <a href="http://127.0.0.1:8000/get_user_info?number=1000" target="_blank" rel="noopener">http://127.0.0.1:8000/get_user_info?number=1000</a> 就可以看到数据库中的数据在页面的渲染</p>
<h3 id="5-后台管理的简单使用"><a href="#5-后台管理的简单使用" class="headerlink" title="5 后台管理的简单使用"></a>5 后台管理的简单使用</h3><p>终端执行命令创建超级管理员并登陆</p>
<figure class="highlight python"><figcaption><span>manage.py createsuperuser```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">然后在http://<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">8000</span>/admin中登陆进入后台管理界面</span><br><span class="line"></span><br><span class="line">例如需要在后台管理我们创建的family_app.user表，做一些常规的增删改查。</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 5.1 创建一个新的工程</span></span><br><span class="line"></span><br><span class="line">`python manage.py startapp family_user_admin`</span><br><span class="line"></span><br><span class="line"> 并将该工程注册到 family/settings.py的INSTALLED_APPS列表中</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 5.2 开发models模块</span></span><br><span class="line"></span><br><span class="line">将我们的family_app.user表结构中需要我们修改的字段映射到发model中</span><br></pre></td></tr></table></figure>
<pre><code>check_status = (
    (0, &apos;不生效&apos;),
    (1, &apos;生效&apos;),
)

class MyUser(models.Model):
    id = models.BigIntegerField(verbose_name=&apos;id&apos;, editable=False, primary_key=True, unique=True)
    number = models.BigIntegerField(verbose_name=&apos;用户number&apos;, editable=True)
    name = models.CharField(verbose_name=&apos;用户名&apos;, max_length=1024, blank=True)
    mobile = models.CharField(verbose_name=&apos;电话&apos;, max_length=1024, blank=True)
    status = models.IntegerField(verbose_name=&apos;用户状态&apos;, choices=check_status)

    class Meta:
        db_table = &apos;user&apos;</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">#### 5.3 开发admin模块</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">将我们model中的需要展示和修改的字段添加到管理界面中</span><br></pre></td></tr></table></figure>
<pre><code>from models import MyUser
class MyUserAdmin(admin.ModelAdmin):
    list_display = (&apos;number&apos;, &apos;name&apos;, &apos;mobile&apos;, &apos;status&apos;)
    search_fields = (&apos;number&apos;, &apos;name&apos;, &apos;mobile&apos;)


    def has_delete_permission(self, request, obj=None):
        return False

admin.site.register(MyUser, MyUserAdmin)</code></pre><p>```</p>
<p>操作完以上步骤后在admin界面中可以看到我们的新增的管理模块MyUsers，点击进去就可以看到配置的信息，可以做增删改查操作</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title>flume1.8在线上业务中的使用和总结</title>
    <url>/2020/05/11/flume1-8%E5%9C%A8%E7%BA%BF%E4%B8%8A%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h4 id="什么是flume？"><a href="#什么是flume？" class="headerlink" title="什么是flume？"></a>什么是flume？</h4><ul>
<li><p>flume是一个日志采集、聚合和传输的系统</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1462670-323b82d3b5790407.jpg?imageMogr2/auto-orient/strip" alt="这里写图片描述"></p>
</li>
</ul>
<h4 id="作用是什么？"><a href="#作用是什么？" class="headerlink" title="作用是什么？"></a>作用是什么？</h4><ul>
<li>作用就是将业务集群上各个机器上的日志收集起来，对数据做集中处理。</li>
</ul>
<h4 id="部署文档"><a href="#部署文档" class="headerlink" title="部署文档"></a>部署文档</h4><ul>
<li>最新版的flume1.8，请参官网 <a href="http://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html</a> 的使用说明，真的很详细。</li>
<li>网上也有flume1.7的搭建教程，Google一下就可以，搭建过程没有太大的区别。</li>
</ul>
<h4 id="前期调研"><a href="#前期调研" class="headerlink" title="前期调研"></a>前期调研</h4><p>在考虑日志的收集之前，我们主要调研了flume和logstash两款产品。当前业界使用较多的是logstash作为日志收集的工具。现将flume和logstash在我们的业务考虑范围内的区别简单罗列：</p>
<ul>
<li>Logstash偏重于字段的预处理；flume偏重数据的传输。</li>
<li>Logstash有插件可以使用，配置比较灵活；flume则是强调用户的自定义开发(输入、存储、输出等)。</li>
<li>Logstash的输入、过滤和输出之间都有缓冲区；flume是有channel作持久化（可以自定义配置）</li>
</ul>
<h4 id="选择使用flume的原因："><a href="#选择使用flume的原因：" class="headerlink" title="选择使用flume的原因："></a>选择使用flume的原因：</h4><ul>
<li>传输数据的可靠性（主要因素）。每一个source和sink都被封装成一个事务存储在channel中，可以保证数据准确的被下游消费。如果下游服务挂掉，flume可以将数据持久化到本地，等待下游服务恢复后在输出。</li>
<li>只传输数据不解析。不会对原始的数据进行过滤和预解析，尽量保证主站机器的资源不被日志服务占据太多。所有的解析操作可以放在下游进行。</li>
<li>多种配置方式。有丰富的数据读取方式，tail、socket、exec等等。数据存储可以在本地或者内存，可以配置各种存储空间大小。多种数据输出方式，输出到hdfs、下游flume、es、kafka等等。</li>
<li>多输入输出。可以同时有多个数据源，也可以同时将数据输出到多个下游。</li>
<li>如果实时性要求不高的话可以采取批量读取的方式。</li>
<li>输出数据时可以对数据进行压缩后输出，存储带hdfs的话可能会需要吧。</li>
<li>有java的api，我们可以自己实现对数据的过滤。</li>
</ul>
<p>以上的调研并不能全面的概括flume的特性，只是它开箱即用的基本特性，其可扩展性很强大。</p>
<h4 id="我们的日志收集系统的整体框架设计"><a href="#我们的日志收集系统的整体框架设计" class="headerlink" title="我们的日志收集系统的整体框架设计"></a>我们的日志收集系统的整体框架设计</h4><p><img src="http://img.blog.csdn.net/20180227212550956?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3NhMTIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="日志收集框架图"></p>
<p>如上图所示，在每个nginx机器上部署一个flume的客户端，将我们关心的日志文件写到到flume的配置文件中，具体的配置可以自行网上查找。</p>
<h4 id="遇到的问题及解决办法"><a href="#遇到的问题及解决办法" class="headerlink" title="遇到的问题及解决办法"></a>遇到的问题及解决办法</h4><p>1、flume的服务挂了 日志数据怎么办？<br>可以采用将服务以守护进程的方式启动，监控进程的状态，日志是后端和nginx实时打在磁盘的，所以就算服务挂了，重启后也是可以读取到日志的对应位置。或者将flume的channel配置成file，就不会出现日志数据丢失的问题。</p>
<p>2、监听的文件fd换了 怎么监控？<br>flume监控的是文件名，并不是fd，所以当原始日志切换切分时，新创建的日志文件只要名称不变，还是可以监控到。</p>
<p>3、当flume的sink配置的是hdfs时，可以选择将数据压缩。flume支持通用的压缩算法。我们采用了gzip的压缩算法，比不压缩节省约70%的磁盘空间。</p>
<h4 id="最最最重要的问题来了"><a href="#最最最重要的问题来了" class="headerlink" title="最最最重要的问题来了"></a>最最最重要的问题来了</h4><p>在flume的sink配置的是hdfs时，请做以下操作，顺序无所谓：</p>
<ul>
<li>flume使用的是hadoop和hdfs中的lib目录下的jar包，所以需要将对应的jar包导入到flume的lib目录下；</li>
<li>导入core-site.xml和hdfs-site.xml文件，如果文件中配置的是hadoop节点的名字，需要将名字和对应的机器ip配置到/etc/hosts中，不然flume找不到；</li>
<li>一定要将hadoop集群中的native目录导入到flume服务端所在机器的环境变量中，命令 export ~/flume/native。原因是Hadoop是使用Java开发的，但是有一些需求和操作并不适合使用java，所以就引入了本地库的概念，通过本地库，Hadoop可以更加高效地执行某一些操作。</li>
</ul>
<p>没有导入的时候一般的操作没有什么问题，但是，使用gzip做数据压缩时就会出现系统环境的问题，导致hadoop集群上hive不能正确的解压缩数据。<br>没有导入native时，gzip压缩的文件使用file查看文件类型时是: gzip compressed data, from FAT filesystem (MS-DOS, OS/2, NT)<br>导入后，gzip压缩的文件使用file查看文件类型时是: gzip compressed data, from Unix。这才是我们想要的压缩文件。<br>所以，一定要导入native！！！千万不要踩坑！！！</p>
]]></content>
      <categories>
        <category>flume</category>
      </categories>
      <tags>
        <tag>flume</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka的可靠性</title>
    <url>/2020/05/11/Kafka%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/</url>
    <content><![CDATA[<p><strong>在使用kafka的时候，我们都知道kafka有很强的可靠性，或者说kafka可以保证消息不丢失。<br>那它是怎么来保证的呢？<br>或者返过来思考，在使用kafka的时候什么情况下会丢失消息呢？</strong></p>
<p>从应用kafka的三个角度来理解kafka的可靠性保证</p>
<h3 id="生产者的可靠性"><a href="#生产者的可靠性" class="headerlink" title="生产者的可靠性"></a>生产者的可靠性</h3><p>在kafka的producer配置时，我们需要配置一些必要的参数来保证生产端的可靠性</p>
<h4 id="确认机制（request-required-acks）"><a href="#确认机制（request-required-acks）" class="headerlink" title="确认机制（request.required.acks）"></a>确认机制（request.required.acks）</h4><p>request.required.acks（下面简写ack），这个参数有三个值，分别是1, 0, -1</p>
<ul>
<li>1：producer在ISR（先不管是什么，下面有说明）中的leader已成功收到的数据并得到确认后发送下一条message。如果leader宕机了，且producer没有重试机制，则会丢失数据。</li>
<li>0：producer无需等待来自broker的确认而继续发送下一批消息。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li>
<li>-1：producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高，但是传输速率有一定的影响。但是这样也不能保证数据不丢失，比如当ISR中只有leader时，这种场景就变成了acks=1的情况</li>
</ul>
<h4 id="发送模式-（producer-type）"><a href="#发送模式-（producer-type）" class="headerlink" title="发送模式 （producer.type）"></a>发送模式 （producer.type）</h4><p>producer.type 这个参数指定了在后台线程中消息的发送方式是同步的还是异步的，如果需要确保消息的可靠性，必须要将producer.type设置为sync。</p>
<ul>
<li>producer.type=sync（默认）。默认是同步方式，所以一般不用配置</li>
<li>producer.type=async，设置异步模式，在producer的内存中数据缓存一定数量时以batch的形式push数据到kafka上，这样会极大的提高broker的性能，但是这样会增加丢失数据的风险。</li>
</ul>
<p>所以生产端要根据实际的业务场景，斟酌可靠性和传输性能，配置合适的参数。</p>
<h3 id="kafka-broker的可靠性"><a href="#kafka-broker的可靠性" class="headerlink" title="kafka broker的可靠性"></a>kafka broker的可靠性</h3><p>kafka server的可靠性保证主要是其健壮的副本策略。调整和副本相关的参数，可以保证kafka的副本策略保证生产环境的数据可靠性要求。从最原始的物理层开始解析</p>
<h4 id="文件存储机制"><a href="#文件存储机制" class="headerlink" title="文件存储机制"></a>文件存储机制</h4><p>kafka中每一类型的消息，我们称之为topic，生产者通过topic向kafka broker发送消息，消费者通过topic从kafka broker中读取消息。</p>
<p>topic在物理层由partition组成，每一个topic可以分成若干个partition。再往下，一个partition在物理层由若干个segment组成。<br>我们一一介绍 topic、partition和segment。在物理层的存储，可以在kafka的部署节点中有一个data目录，可以看到每个topic对应的partition，进入partition之后可以看到具体的segment结构。也可以通过命令来查看分区信息：<code>sh kafka-topics.sh --zookeeper localhost:2181/kafka --topic topicName --describe</code><br>无论是通过命令还是直接在目录下查看，可以看到每个partition的命名都是通过<strong>topic+有序序号</strong>命名的，最大的序号是partition数-1。partition是实际物理上的概念，而topic是逻辑上的概念。</p>
<p>partition再细分的segment就是数据的最小存储单位。每个partition相当于一个巨型文件被平均分配到多个大小相等的segment数据文件中（每个segment 文件中消息数量不一定相等）这种特性也方便old segment的删除，即方便已被消费的消息的清理，提高磁盘的利用率。每个partition只需要支持顺序读写就行，segment的文件生命周期由服务端配置参数决定（详细的参数配置参考官网）。</p>
<p>在kafka数据存储目录下，可以看到每个partition(/data/topic-01)下的数据存储细节，每一个segment文件都是由两部分组成的，<em>.index文件和</em>.log文件，分别对应segment的索引文件和数据文件，文件的命名规则是：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值，数值大小为64位，20位数字字符长度，没有数字用0填充，如下图所示：<br> <strong><em>我是图</em></strong><br>partition中如何通过offset查找message，我们暂不详细说明，后面专门写文件介绍这块</p>
<p>参考：</p>
<ul>
<li><a href="https://www.cnblogs.com/huxi2b/tag/Kafka/" target="_blank" rel="noopener">https://www.cnblogs.com/huxi2b/tag/Kafka/</a></li>
<li><a href="http://www.importnew.com/25247.html" target="_blank" rel="noopener">http://www.importnew.com/25247.html</a></li>
</ul>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>google的tensor2tensor的学习和使用</title>
    <url>/2020/05/11/google%E7%9A%84tensor2tensor%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul>
<li>tensor2tensor（t2t）是google基于tensorflow新开源的深度学习库，该库将深度学习所需要的元素（数据集、模型、学习率、超参数等）封装成标准化的统一接口，在使用其做模型训练时可以更加的灵活。</li>
</ul>
<h3 id="当前环境"><a href="#当前环境" class="headerlink" title="当前环境"></a>当前环境</h3><ul>
<li>mac 10.13.3</li>
<li>tensorflow 1.6.0</li>
<li>tensor2tensor 1.5.5</li>
</ul>
<h3 id="安装模块"><a href="#安装模块" class="headerlink" title="安装模块"></a>安装模块</h3><ul>
<li>源码下载：<a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">https://github.com/tensorflow/tensor2tensor</a></li>
<li>sudo pip install tensorflow==1.6.0</li>
<li>sudo pip install tensor2tensor==1.5.5</li>
</ul>
<h3 id="开启学习之旅"><a href="#开启学习之旅" class="headerlink" title="开启学习之旅"></a>开启学习之旅</h3><p>在下载的源码中有自带的一些简单的测试样例。如mnist,，可以参考<a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb</a><br>来做初步的了解。</p>
<p>同时t2t支持自定义的样本数据和自定义的参数配置，下面以我自定义了一个训练样本开始介绍。</p>
<p>已将下述的代码上传：<a href="https://download.csdn.net/download/csa121/10672326" target="_blank" rel="noopener">https://download.csdn.net/download/csa121/10672326</a><br>根据下述的介绍也可以自己搭建一个环境的。</p>
<h4 id="0-目录结构"><a href="#0-目录结构" class="headerlink" title="0.目录结构"></a>0.目录结构</h4><p>因为有需要注意的点，先看下我自定义样本的目录结构：<br><img src="http://img.blog.csdn.net/20180318200525009?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3NhMTIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="目录结构"></p>
<p>decoder：预测要用到的目录<br>rawdata：原始样本存放的目录<br>self_data：原始样本格式化后存放的目录<br>self_script：自定义problem脚本存放的目录<br>train：训练出来的模型和导出的模型存放的目录</p>
<p>注：只是为了后续介绍的更清楚才说明的目录结构，不是t2t要求的目录结构。</p>
<h4 id="1-需求"><a href="#1-需求" class="headerlink" title="1.需求"></a>1.需求</h4><p>训练一些评论和标签样本，生成一个模型，可以给新的评论打一个标签</p>
<h4 id="2-样本"><a href="#2-样本" class="headerlink" title="2.样本"></a>2.样本</h4><p>评论样本 rawdata/q.txt：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">内容很多很棒</span><br><span class="line">好老师！有耐心！培养孩子兴趣！赞一个</span><br><span class="line">课程很精彩，老师会结合自身作为案例进行分享</span><br><span class="line">老师很幽默</span><br><span class="line">老师的能力值得肯定</span><br><span class="line">喜欢上老师的数学课</span><br><span class="line">老师上课气氛特别好</span><br><span class="line">每次听完老师的课都觉得让自己又丰富了许多</span><br><span class="line">挺善于沟通的,比较容易接受</span><br><span class="line">观点很新颖,谢谢老师</span><br></pre></td></tr></table></figure>

<p>标签样本 rawdata/a.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">授课熟练</span><br><span class="line">态度认真负责</span><br><span class="line">授课熟练</span><br><span class="line">幽默风趣</span><br><span class="line">性价比高</span><br><span class="line">幽默风趣</span><br><span class="line">上课气氛活跃</span><br><span class="line">内容新颖有用</span><br><span class="line">性价比高</span><br><span class="line">内容新颖有用</span><br></pre></td></tr></table></figure>
<h4 id="3-编写自定义的problem"><a href="#3-编写自定义的problem" class="headerlink" title="3.编写自定义的problem"></a>3.编写自定义的problem</h4><p>self_script/my_problem.py</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding&#x3D;utf-8</span><br><span class="line">from tensor2tensor.utils import registry</span><br><span class="line">from tensor2tensor.data_generators import problem, text_problems</span><br><span class="line"></span><br><span class="line">#自定义的problem一定要加该装饰器，不然t2t库找不到自定义的problem</span><br><span class="line">@registry.register_problem</span><br><span class="line">class MyProblem(text_problems.Text2TextProblem):</span><br><span class="line">    @property</span><br><span class="line">    def approx_vocab_size(self):</span><br><span class="line">        return 2**11</span><br><span class="line"></span><br><span class="line">    @property</span><br><span class="line">    def is_generate_per_split(self):</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">    @property</span><br><span class="line">    def dataset_splits(self):</span><br><span class="line">        return [&#123;</span><br><span class="line">            &quot;split&quot;: problem.DatasetSplit.TRAIN,</span><br><span class="line">            &quot;shards&quot;: 9,</span><br><span class="line">        &#125;, &#123;</span><br><span class="line">            &quot;split&quot;: problem.DatasetSplit.EVAL,</span><br><span class="line">            &quot;shards&quot;: 1,</span><br><span class="line">        &#125;]</span><br><span class="line"></span><br><span class="line">    def generate_samples(self, data_dir, tmp_dir, dataset_split):</span><br><span class="line">        del data_dir</span><br><span class="line">        del tmp_dir</span><br><span class="line">        del dataset_split</span><br><span class="line">		#读取原始的训练样本数据</span><br><span class="line">        q_r &#x3D; open(&quot;.&#x2F;rawdata&#x2F;q.txt&quot;, &quot;r&quot;)</span><br><span class="line">        a_r &#x3D; open(&quot;.&#x2F;rawdata&#x2F;a.txt&quot;, &quot;r&quot;)</span><br><span class="line"></span><br><span class="line">        comment_list &#x3D; q_r.readlines()</span><br><span class="line">        tag_list &#x3D; a_r.readlines()</span><br><span class="line">        q_r.close()</span><br><span class="line">        a_r.close()</span><br><span class="line">        for comment, tag in zip(comment_list, tag_list):</span><br><span class="line">            comment &#x3D; comment.strip()</span><br><span class="line">            tag &#x3D; tag.strip()</span><br><span class="line">            yield &#123;</span><br><span class="line">                &quot;inputs&quot;: comment,</span><br><span class="line">                &quot;targets&quot;: tag</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<p>self_script/<strong>init</strong>.py</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from . import my_problem</span><br></pre></td></tr></table></figure>

<p>需要注意的点：<br>（1）一定要在<strong>init</strong>.py文件中引入模块，否则t2t的命令找不到自定义的problem；</p>
<p>（2）自定义的problem文件名一定要和脚本中的class名保持一致，如：文件名是my_problem，类名需要是MyProblem，否则t2t的命令找不到自定义的problem。希望后续的版本不会有这个问题吧。</p>
<h4 id="4-格式化样本"><a href="#4-格式化样本" class="headerlink" title="4.格式化样本"></a>4.格式化样本</h4><p>要将原始的样本数据转换成t2t自己的数据集格式（TFRecord），使用t2t-datagen命令执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">t2t-datagen --t2t_usr_dir&#x3D;self_script --problem&#x3D;my_problem --data_dir&#x3D;.&#x2F;self_data</span><br></pre></td></tr></table></figure>
<p>格式化的数据会在self_data目录下生成一些文件如下：</p>
<p><img src="http://img.blog.csdn.net/20180318202301389?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3NhMTIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="格式化数据文件"></p>
<p>后续我们的训练就是读这些文件。</p>
<h4 id="5-训练"><a href="#5-训练" class="headerlink" title="5.训练"></a>5.训练</h4><p>使用t2t-trainer命令对格式化样本进行训练：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">t2t-trainer --t2t_usr_dir&#x3D;self_script --problem&#x3D;my_problem --data_dir&#x3D;.&#x2F;self_data --model&#x3D;lstm_seq2seq_attention --hparams_set&#x3D;lstm_attention --output_dir&#x3D;.&#x2F;train</span><br></pre></td></tr></table></figure>
<p>我们使用的模型是lstm_seq2seq_attention模型，使用的超参数集是lstm_attention。因为还在学习阶段，就没有特地去选择模型。</p>
<p>需要注意的点：<br>（1）如果在训练过程中有如下报错：</p>
<p><img src="http://img.blog.csdn.net/20180318203105033?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3NhMTIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="训练报错"></p>
<p>说明当前tensor2tensor和tensorflow的版本兼容有问题，需要更换两者的版本，经过查阅tensor2tensor在github的代码提交和其他信息，试验出来tensor2tensor==1.5.3和tensorflow==1.4.1这两个版本组合是没有问题的。有报错的可以把两者版本降低一下。</p>
<p>（2）在训练过程中我没有指定训练的次数和打印准确率的步数，t2t默认是训练1000次打印一次准确率。如果感觉准确率符合预期的话，可以直接kill掉训练任务。t2t会自动保存最新的训练模型。</p>
<h4 id="6-预测"><a href="#6-预测" class="headerlink" title="6.预测"></a>6.预测</h4><p>使用t2t-decoder命令对训练好的样本进行预测<br>先看下预测的样本：<br>decoder/q.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">老师很幽默</span><br><span class="line">非常好 讲的很详细 很幽默哈哈哈</span><br><span class="line">第一次听！讲得还挺清楚，只是不清楚后面怎么安排呢</span><br></pre></td></tr></table></figure>
<p>预测是命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">t2t-decoder --t2t_usr_dir&#x3D;self_script --problem&#x3D;my_problem --data_dir&#x3D;.&#x2F;self_data --model&#x3D;lstm_seq2seq_attention --hparams_set&#x3D;lstm_attention --output_dir&#x3D;.&#x2F;train --decode_hparams&#x3D;&quot;beam_size&#x3D;4,alpha&#x3D;0.6&quot; --decode_from_file&#x3D;decoder&#x2F;q.txt --decode_to_file&#x3D;decoder&#x2F;a.txt</span><br></pre></td></tr></table></figure>
<p>可以在你指定的decode_to_file文件下看到预测的结果是否符合预期</p>
<h4 id="7-导出模型"><a href="#7-导出模型" class="headerlink" title="7.导出模型"></a>7.导出模型</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">t2t-exporter --t2t_usr_dir&#x3D;self_script --problems&#x3D;my_problem --data_dir&#x3D;.&#x2F;self_data --model&#x3D;lstm_seq2seq_attention --hparams_set&#x3D;lstm_attention --output_dir&#x3D;.&#x2F;train</span><br></pre></td></tr></table></figure>
<p>需要注意的点：<br>（1）github中t2t的源码中有提到导出功能只支持tensorflow 1.5+，所以如果在训练过程中有降低了tensorflow版本的操作，还需要把版本升到1.5+；</p>
<p>（2）注意导出命令中的<strong>problems</strong>=my_problem参数，前面训练时使用的是<strong>problem</strong>=my_problem，<strong>导出时需要加problem参数名要加s</strong>。不知道t2t中为什么会存在这种不兼容的情况，希望后续会修复这个参数的问题吧。</p>
<h4 id="8-搭建一个常驻内存的预测服务"><a href="#8-搭建一个常驻内存的预测服务" class="headerlink" title="8.搭建一个常驻内存的预测服务"></a>8.搭建一个常驻内存的预测服务</h4><p>搭建服务时请确保mac上安装了brew，没有安装的请先自行安装brew。后续步骤如下：<br>（1）安装tensorflow-serving-api</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo pip install tensorflow-serving-api</span><br></pre></td></tr></table></figure>
<p>（2）安装Bazel<br>bazel是google的一个编译工具，类似于Make。我们需要使用它对源码进行编译出一个tensorflow_model_server二进制文件。执行：brew install bazel</p>
<p>（3）下载serving源码<br>我们需要使用bazel对源码进行编译，所以需要先下载该源码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone --recurse-submodules https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;serving</span><br></pre></td></tr></table></figure>

<p>（4）创建tensorflow_serving</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd serving</span><br><span class="line">bazel build tensorflow_serving&#x2F;</span><br></pre></td></tr></table></figure>

<p>（5）编译出一个用来启动服务的tensorflow_model_server的二进制文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bazel build -c opt &#x2F;&#x2F;tensorflow_serving&#x2F;model_servers:tensorflow_model_server</span><br></pre></td></tr></table></figure>
<p>注：时间比较长，编译大概用了一个多小时吧</p>
<p>（6）配置命令<br>将tensorflow_model_server命令起个别名指定到目录，这样就不用在特定的目录下执行启动服务的操作了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim ~&#x2F;.bashrc</span><br><span class="line">alias tensorflow_model_server&#x3D;&#39;~&#x2F;serving&#x2F;bazel-bin&#x2F;tensorflow_serving&#x2F;model_servers&#x2F;tensorflow_model_server&#39;</span><br><span class="line">source ~&#x2F;.bashrc</span><br></pre></td></tr></table></figure>
<p>（7）启动server</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tensorflow_model_server --port&#x3D;9000 --model_name&#x3D;lstm_seq2seq_attention --model_base_path&#x3D;~&#x2F;self_t2t&#x2F;train&#x2F;export&#x2F;Servo</span><br></pre></td></tr></table></figure>
<p>经过以上的步骤，就可以启动一个常驻内存的预测服务了。</p>
<h4 id="9-客户端发请求预测"><a href="#9-客户端发请求预测" class="headerlink" title="9.客户端发请求预测"></a>9.客户端发请求预测</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">t2t-query-server --server&#x3D;127.0.0.1:9000 --servable_name&#x3D;lstm_seq2seq_attention --t2t_usr_dir&#x3D;self_script --problem&#x3D;my_problem --data_dir&#x3D;.&#x2F;self_data</span><br></pre></td></tr></table></figure>

<h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><ul>
<li><p>经过上述的所有操作，对t2t的使用上有了一个初步的了解，在后续的使用中可以根据各自不同的业务场景自定义不同的problem、更换model和hparams。</p>
</li>
<li><p>在使用的过程中，发现目前t2t和tf的版本间兼容性还不是很好，相信后续应该会更完善吧。</p>
</li>
<li><p>虽然t2t将现有的一些主流模型做了封装，我们可以不用关注模型的生成，但是我们也有必要多了解其背后的实现原理。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
        <tag>tensor2tensor</tag>
      </tags>
  </entry>
  <entry>
    <title>hdfs Cannot obtain block length for LocatedBlock异常的解决</title>
    <url>/2020/05/11/%E4%BB%8E0%E5%AD%A6java%E7%AC%AC1%E7%AF%87-%E5%AF%B9java%E7%9A%84%E7%B2%97%E6%B5%85%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h4 id="问题的发现"><a href="#问题的发现" class="headerlink" title="问题的发现"></a>问题的发现</h4><p>在备份hdfs的数据到本地磁盘时，使用了get命令，结果报错了，具体的错误就是Cannot obtain block length for LocatedBlock这个异常。发现这个问题之后就开始解决问题。</p>
<h4 id="问题出现的原因"><a href="#问题出现的原因" class="headerlink" title="问题出现的原因"></a>问题出现的原因</h4><p>写hdfs的上游是flume，所以就去查出错数据当天是否调整过flume服务。通过flume的日志发现当天有写hdfs时候，datanode没有响应的错误日志，正在写的日志文件就没有正常的关闭。</p>
<p>这里就出现了hdfs的租约未被释放的问题，租约就是<code>在HDFS中，当每次客户端用户往某个文件中写入数据的时候，为了保持数据的一致性，此时其它客户端程序是不允许向此文件同时写入数据的</code>，租约的信息是存在namenode中的，也就是说当hdfs系统被关闭时，flume还在继续写该文件，同时也会报错，文件还是处于打开状态。</p>
<p>所以我们要解决这个问题就需要释放租约。</p>
<h4 id="恢复租约的方式"><a href="#恢复租约的方式" class="headerlink" title="恢复租约的方式"></a>恢复租约的方式</h4><p>首先先查看有哪些文件是租约没有释放的<br><code>hadoop fsck /hafs/path -openforwrite</code><br>然后执行<br><code>hdfs debug recoverLease -path</code><br>释放租约</p>
<p>如果未被释放租约的文件太多的话，可以执行批量释放操作<br><code>hadoop fsck /hafs/path -openforwrite | egrep -v &#39;^\.+$&#39; | egrep &quot;MISSING|OPENFORWRITE&quot; | grep -o &quot;/[^ ]*&quot; | sed -e &quot;s/:$//&quot; | xargs -i hdfs debug recoverLease -path {}</code></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>该问题的出现主要是下游关闭时上游还在写，导致租约没有释放掉。在以后的升级或者重启hdfs时，需要提前先把flume或者其他上游写hdfs操作停止后，在执行hdfs系统的操作，才可以避免该问题的出现。</p>
]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>文件租约</tag>
      </tags>
  </entry>
  <entry>
    <title>scrapy写爬虫注意事项</title>
    <url>/2020/05/11/scrapy%E5%86%99%E7%88%AC%E8%99%AB%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
    <content><![CDATA[<h4 id="前段时间有个爬虫的需求，爬的什么网站的数据就不说了，简单介绍下在学习scrapy这中间踩的坑吧。"><a href="#前段时间有个爬虫的需求，爬的什么网站的数据就不说了，简单介绍下在学习scrapy这中间踩的坑吧。" class="headerlink" title="前段时间有个爬虫的需求，爬的什么网站的数据就不说了，简单介绍下在学习scrapy这中间踩的坑吧。"></a>前段时间有个爬虫的需求，爬的什么网站的数据就不说了，简单介绍下在学习scrapy这中间踩的坑吧。</h4><blockquote>
<p>1、在爬取数据的时候，一定要想办法将爬虫伪装成一个浏览器，可以通过设置cookie和请求头的信息。这个具体的方法很多，随便百度一个关键词“scrapy设置请求头”，就可以出来一大堆答案。裸奔的话频率小点没啥事，但是访问频率比较高的话就会被302掉。甚至会被短时间内封掉ip，建议设置一个请求头比较保险。</p>
</blockquote>
<blockquote>
<p>2、使用scrapy时，要学会使用meta来传参。</p>
</blockquote>
<blockquote>
<p>3、要深入理解yield的用法。</p>
</blockquote>
<blockquote>
<p>4、item的使用尽量将需要的字段给他，不要给无关紧要的字段。</p>
</blockquote>
<blockquote>
<p>5、碰到异步请求的页面是，耐心找找异步请求的链接获取格式。一般来讲，请求<br>的链接都是固定的，只是某一个相关的参数不同。拼接请求就可以了。</p>
</blockquote>
<blockquote>
<p>6、碰到js渲染的页面时，需要使用phantomjs来加载js渲染后页面，phantomjs更像一个隐藏的浏览器，能获取到最全面的页面信息，使用时需要自己写一个js加载文件。网上很多。最便捷的就是通过标准输出将页面返回给主逻辑。</p>
</blockquote>
]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>python数据清洗流程和注意点</title>
    <url>/2020/05/11/python%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E6%B5%81%E7%A8%8B%E5%92%8C%E6%B3%A8%E6%84%8F%E7%82%B9/</url>
    <content><![CDATA[<h4 id="最近一直在做数据清洗业务。终于告一段落，简单的总结记录一下最近工作。方便后续查看吧。"><a href="#最近一直在做数据清洗业务。终于告一段落，简单的总结记录一下最近工作。方便后续查看吧。" class="headerlink" title="最近一直在做数据清洗业务。终于告一段落，简单的总结记录一下最近工作。方便后续查看吧。"></a>最近一直在做数据清洗业务。终于告一段落，简单的总结记录一下最近工作。方便后续查看吧。</h4><p>具体的工作流程就是将数据从hive或者原始日志中清洗、整理后入库。然后供业务方使用和展示。</p>
<blockquote>
<h3 id="开发前："><a href="#开发前：" class="headerlink" title="开发前："></a>开发前：</h3></blockquote>
<p>当你接到一个需求时，先考虑3点：</p>
<ul>
<li>1、你是否理解每一个字段的含义和每一个字段的存放位置（在原始日志中or现有的表中）。一定要先了解清楚每一个字段，这关乎你后续工作是否可以顺利进行。特别是有些数据是已有的，不需要重复开发清洗。多了解一些有利于后续的工作。</li>
</ul>
<ul>
<li><p>2、在理清楚1中的关系之后，将需求中的字段按照需求设计表或者接口。一定要在开发之前先设计好接口或者要写入的表结构。这一点非常重要，不要着急的写程序！不要着急的写程序！！不要着急的写程序！！！当你这一步完成的时候，你已经完成了30%的工作量。</p>
<p>  <code>根据以往经验来看，每一个需求都会有各种筛选条件（如性别、身份类型等）和要呈现的数据。所以我们可以将需求字段分为两部分：筛选字段和展示字段。筛选字段的各种条件状态一定要考虑充分，不要有遗漏或者重复包含。</code></p>
</li>
</ul>
<ul>
<li>3、了解需求中的数据的更新状态。一般来讲有一次性需求、小时级更新、天级更新和月级别更新几种更新周期。根据不同的更新周期设计不同的调用方式。不能只考虑未来的脚本执行，还需要考虑历史数据回溯等情况。设计一种方便、灵活、简单调度方法，有利于未来数据维护的便捷。</li>
</ul>
<h3 id="开发中："><a href="#开发中：" class="headerlink" title="开发中："></a>开发中：</h3><p>在上面的三点的充分考虑之后，开发脚本基本就是顺水推舟了。在设计表结构的时候，你就已经考虑到了脚本中应该怎么实现需求中的筛选字段和展示字段，所以在后续的开发过程中基本上逻辑方向不会有任何问题。但是在技术实现层面上，需要注意几个常见小细节吧。</p>
<ul>
<li>1、在python内部实现好的几种数据结构中，最常用到的应该是dict、list和set（dict和list的杂交产物）三种了。要搞清楚这三种数据结构的特性，才能在相适应的场景中发挥其作用。举个栗子：当仅需要判断集合中是否包含某一值时，可以用set实现集合，不适宜用list。因为set的时间复杂度是O(1)，更快的能得到结果，list就会比较慢，数据量很大的时候list超级慢，因为它是在遍历整个集合。建议先熟悉这三种基础的数据结构的用法和区别。</li>
</ul>
<ul>
<li>2、在清洗脚本过程中可能会遇到字符集编码错误的问题。一般解决的办法是，先打印出来当前的字符集编码类型，当你想要将某一类型转成utf8时，先转成unicode，再转成utf8。unicode是python字符集编码的中转站。这个google一下就有很多的解决办法。</li>
</ul>
<pre><code>强调一点就是在遇到中文乱码的问题时，先将字符串用unicode()函数转一次就好了，亲尝有效。</code></pre><ul>
<li>3、当我们需要入库的数据量较大时（2k条以上吧）直接insert会比较慢，而且频繁入库会影响数据同步，建议先将数据写入到本地，然后load到数据库中。速度非常快！！</li>
</ul>
<blockquote>
<p>三、开发后：</p>
</blockquote>
<ul>
<li><p>开发完成后是调试和验证数据准确性的阶段。调试不用多说，根据报错信息自行google就可以。</p>
</li>
<li><p>行百里者半九十，数据校验部分很重要。结合业务场景和上游数据来校验当前数据是最基本的方法，比如校验数据的总量、各条件下的数据量、随机抽查部分数据的正确性等都是校验数据的方式。</p>
</li>
<li><p>校验数据一定要胆大心细：误差较大就要大胆推理哪儿有问题，不一定是你的脚本有问题，也有可能是上游数据就有问题了；最基础的字段也需要仔细验证，不要因为是基础通用字段就认为一定没有问题。</p>
</li>
</ul>
<h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><p>整个过程回想起来没有那么多的技术含量，但是前期的需求分析设计，中期的开发调试和后期的数据校验全是一个人的工作，所以需要你细心+耐心。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>etl</tag>
      </tags>
  </entry>
  <entry>
    <title>从0学java第1篇--对java的粗浅理解</title>
    <url>/2020/05/11/%E4%BB%8E0%E5%AD%A6java%E7%AC%AC1%E7%AF%87-%E5%AF%B9java%E7%9A%84%E7%B2%97%E6%B5%85%E7%90%86%E8%A7%A3-1/</url>
    <content><![CDATA[<h3 id="对java的粗浅理解"><a href="#对java的粗浅理解" class="headerlink" title="对java的粗浅理解"></a>对java的粗浅理解</h3><p>对java有过简单了解的人都听说过java是”一次书写，到处运行”这一大特点，这个说的就是java的跨平台的特性。但是这种特性并不只是java才有的，java只是比较成熟一些而已。</p>
<p>所谓的”一次书写，到处运行”指的是我们编写好的程序，通过javac编译后，变成<em>.class文件的字节码，</em>.class就是可以到处运行的文件，但是这种文件不可以直接在机器上执行，需要使用jvm这种跨平台的抽象环境，将字节码转化成目标机器代码，这样就可以实现导出运行了。</p>
<h3 id="编译执行还是解释执行？"><a href="#编译执行还是解释执行？" class="headerlink" title="编译执行还是解释执行？"></a>编译执行还是解释执行？</h3><p>对java而言，在程序执行的时候，jvm将字节码解释成机器可以识别的机器码。但是在我们通常使用的jvm中，都提供了 JIT（Just-In-Time）编译器，JIT可以在运行的时候将热点代码编译成机器码，这种情况下热点代码就属于编译执行了。</p>
<h3 id="常见的名词"><a href="#常见的名词" class="headerlink" title="常见的名词"></a>常见的名词</h3><p>在开发过程中我们经常会听到javac、jvm、jre、jdk这些名词，我们理一下他们都是什么。</p>
<ul>
<li><p>javac是一个编译器，用于将我们编写好的代码编译成以.class为后缀的字节码。</p>
</li>
<li><p>jvm就是java虚拟机，我们写好的代码并不直接在真实的目标机器上执行，而是通过javac编译后生成字节码，java虚拟机会把这些字节码解释成目标机器可以识别的机器码执行。</p>
</li>
<li><p>jre就是java运行的环境，在jvm解释字节码的时候，jvm需要调用一些解释所必须的类库，这些必要的类库都是在jre的lib中。所以可以简单的理解为jre包含jvm和所需的lib两部分。</p>
</li>
<li><p>jdk是java的一个开发工具包，我们在开发java程序之前，都会安装一个jdk，jdk主要包含javac、jre和一些类库。</p>
</li>
</ul>
<p>以上的关系可以看出，jdk包含了jre，jre包含了jvm。jdk包含了编译必须使用的javac。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>java内存模型概述</title>
    <url>/2020/05/13/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h2><p>Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而一直存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。如下图所示：</p>
<img src="https://img-blog.csdnimg.cn/20200512233118835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NzYTEyMQ==,size_5,color_FFFFFF,t_70#pic_center" alt="图片替换文本" width="400" height="300" align="bottom" />


<hr>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p>程序计数器占用整个数据区较小的一块空间，可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的模型中，程序计数器的作用就是字节码解释器通过改变计数器的值来选取下一条要执行的指令。在代码层面上，<strong>我们经常用到的分支（if…else…）、循环、跳转、异常处理、线程恢复等基础功能都依赖这个计数器完成</strong>。</p>
<p>在java虚拟机中的多线程是通过线程轮流切换，分配处理器的执行时间来实现的。在任何一个确定的时刻，对于一个处理器（多核的机器就是其中的一个核），都只会执行一个线程中的一个指令，当该线程的cpu时间片用完需要让出计算资源时候，需要保存该线程当前执行位置，以便下次能够从正确的位置恢复执行，因此每个线程都有独立的程序计数器，且相互独立存储，互不影响。所以程序计数器是<strong>每个线程的私有区域</strong>。</p>
<p>如果线程执行的是一个java方法，计数器记录的是程序正在执行的字节码指令所在的位置，如果执行的是一个native方法，计数器的值是空值</p>
<hr>
<h2 id="java虚拟机栈（jvm-stack）"><a href="#java虚拟机栈（jvm-stack）" class="headerlink" title="java虚拟机栈（jvm stack）"></a>java虚拟机栈（jvm stack）</h2><p>jvm stack也是<strong>线程私有</strong>的，生命周期和线程一样，用来描述java方法执行时候的线程内存模型。</p>
<p>每个方法在执行的时候都会同步创建一个栈帧（stack frame）用来存储方法内部的局部变量表、操作数栈、动态链接、方法出口等信息。每个方法被调用知道执行完毕的过程，就是一个栈帧在jvm stack 入栈到出栈的过程</p>
<hr>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p>本地方法栈和jvm stack的作用类似。区别在于，jvm stack为虚拟机执行java方法（字节码）服务，本地方法栈则是为虚拟机执行本地方法服务，也是<strong>线程私有</strong>的</p>
<hr>
<h2 id="java-堆（GC-Heap）"><a href="#java-堆（GC-Heap）" class="headerlink" title="java 堆（GC Heap）"></a>java 堆（GC Heap）</h2><p>从java应用程序的角度来说，jav堆是java应用程序所管理的最大的一块内存，<strong>被所有的线程共享</strong> ，在虚拟机启动时创建。java堆的<strong>唯一</strong>作用就是<strong>存放对象实例</strong>，java的世界里，几乎所有的对象实例都在这里分配内存。</p>
<p><strong>java堆是垃圾回收器管理的一块区域</strong>。</p>
<p>从垃圾回收的角度看，现代的垃圾回收器都是采用的分代回收理论设计的，就是我们熟悉的<strong>新生代、老年代、永久代、Eden空间、From Survivor空间、To Survivor空间等</strong>名词。在G1回收器出现为界限，之前的回收器，尤其是业界绝对主流的HotSpot虚拟机，都是采用这种经典分代的设计思想；但是到了如今，垃圾回收技术已不可同日而语，HotSpot中也出现了不采用分代设计的垃圾回收器，所以不能再按照上面的经典分代方式看待了。</p>
<p>从内存分配的角度看，所有线程共享的java堆可以划分出多个线程私有的分配缓冲区，有利于提升对象分配时的效率。但是无论什么角度，何种划分，都不能改变java堆存储内容的特点：<strong>存储的都是对象的实例</strong></p>
<hr>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>方法区和java堆一样，是<strong>线程共享</strong>的内存区域，用于存储被虚拟机加载的<strong>类型信息、常量、静态变量、及时编译器编译后的代码缓存</strong>等。方法区还有一个别名叫做<strong>非堆</strong>，目的就是要和java堆做区分。</p>
<hr>
<h2 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h2><p>运行时常量池属于方法区的一部分，class文件中除了类的版本、字段、方法、接口等描述信息之外，还有一项信息是<strong>常量池表</strong>，用来<strong>存放编译期间生成的各种字面量和符号引用</strong>，这部分内容将在类加载后存放在方法区的运行时常量池。</p>
<p>运行时常量池具有动态性，即不仅仅可以存放编译期产生的常量，在运行期间的常量也可以放入池中。这种特性在代码被利用的较多的就是String类的intern()方法</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>线程共享的内存区域：java堆、方法区（包含运行时常量池）</li>
<li>线程私有的内存区域：程序计数器、jvm stack、本地方法栈</li>
</ul>
<p>具体每个模块的具体功能和原理，后面分模块详细学习之后再做总结</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
</search>
